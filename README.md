---
title: "RideCastAI2.0"
emoji: "ğŸš•"
colorFrom: "red"
colorTo: "yellow"
sdk: streamlit
sdk_version: "1.35.0"
app_file: ui/app.py
pinned: true
---

# ğŸš• RideCastAI 2.0 â€” Real-Time Fare & ETA Predictor with Drift Recovery and Latency Optimization

[![Built with Streamlit](https://img.shields.io/badge/Built%20with-Streamlit-red?logo=streamlit)](https://streamlit.io)  
[![Real-Time ML](https://img.shields.io/badge/ML-Online%20Learning-blue?logo=scikit-learn)]()  
[![Deployed on Hugging Face](https://img.shields.io/badge/Hosted%20on-HuggingFace-orange?logo=huggingface)](https://huggingface.co/spaces/rajesh1804/RideCastAI2.0)  
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> ğŸš¦ **RideCastAI 2.0** is a production-grade real-time ML system that predicts ride fares & ETAs, detects input/output drift, updates models live, and tracks latency â€” simulating a dynamic dispatch engine like Uber, Lyft, or Grab.

ğŸ¯ Designed for top-tier AI infrastructure roles where **adaptability, performance, and monitoring** are key.

---

## âš¡ï¸ Whatâ€™s New in 2.0

| Feature                     | 1.0                               | ğŸš€ 2.0 Upgrade                                    |
|----------------------------|-----------------------------------|--------------------------------------------------|
| Prediction Scope           | Static fare & ETA prediction      | ğŸ” Real-time prediction with async ingestion     |
| Drift Detection            | None                              | âœ… Input + Output drift with visual alerts       |
| Model Adaptation           | Offline model                     | âœ… Online learning with `river`                  |
| Caching & Inference        | None                              | âœ… ONNX + Joblib caching + asyncio               |
| Latency Tracking           | No                                | âœ… Real-time latency chart                       |
| Error Debugging            | No                                | âœ… Live top-5 worst predictions                  |
| UI                         | Basic chart                       | âœ… Tabbed Streamlit dashboard with toggles       |
| Deployability              | Basic                             | âœ… Free-tier deployable on Hugging Face          |

---

## ğŸ“Š Architecture Overview

<p align="center">
  <img src="https://github.com/rajesh1804/RideCastAI2.0/raw/main/assets/RideCastAI2.0-architecture.png" alt="RideCastAI2.0 System Flow" width="750"/>
</p>

```text
Rides (CSV/Simulated) 
â†’ Feature Preprocessing
â†’ Model Inference (ONNX / River)
â†’ Caching Layer (Joblib)
â†’ Output Metrics Tracker (MAE / RMSE / Drift)

â†³ Input Drift Detector (HalfSpaceTrees)
â†³ Output Drift Detectors (KSWIN, ADWIN)
â†³ Online Learner (River LinearRegression)
â†³ Latency Tracker (Async + Retry logic)

â†³ Streamlit UI with Live Dashboard:
   - Prediction + Drift + Latency Tabs
   - Drift Injection / Online Update Toggle
   - Top-5 Error Viewer
   - Logs + Trace Overlay
```

---

## ğŸŒŸ Key Features

âœ… **Real-Time Fare & ETA Prediction**  
âœ… **Online Learning (River)** â€” self-adapts to incoming data  
âœ… **Input Drift Detection** (HalfSpaceTrees)  
âœ… **Output Drift Detection** (KSWIN, ADWIN)  
âœ… **ONNX-Optimized Model + Joblib Caching**  
âœ… **Live Top-5 Worst Prediction Viewer**  
âœ… **Latency Visualization per Batch**  
âœ… **Drift Injection Toggle for Testing**  
âœ… **Fully Modular Streamlit UI**  
âœ… **Free-tier Deployable** (No LLMs required)

---

## ğŸ§  Component Stack

> Each module is modular, production-grade, and latency-aware.

| Component            | Role                                         | Tech Stack                |
|----------------------|----------------------------------------------|---------------------------|
| ğŸš• Predictor          | Predicts fare & ETA                         | `scikit-learn`, `onnx`, `river` |
| ğŸ§  Drift Detectors    | Input (HalfSpaceTrees), Output (KSWIN/ADWIN) | `river.drift`             |
| â™»ï¸ Online Learner     | Updates model weights per ride              | `river.linear_model.LinearRegression` |
| ğŸ’¾ Caching            | Stores past predictions for reuse           | `joblib`                  |
| ğŸ•’ Latency Tracker    | Logs inference time and averages            | `time`, `asyncio`         |
| ğŸ“ˆ Visual Overlay     | RMSE, Drift Flags, Top-5 Errors             | `matplotlib`, `seaborn`   |
| ğŸ§ª Drift Injector     | Force anomaly to test system recovery       | Manual + Config toggle    |
| ğŸ–¥ï¸ UI Layer           | Live dashboard with tabs                    | `Streamlit`               |

---

## ğŸ” How It Works

- Ingests a real-time ride (or simulated stream)
- Featurizes and routes through predictor
- Monitors:
  - ğŸš¨ Input Drift via HalfSpaceTrees
  - ğŸ“‰ Output Drift via KSWIN & ADWIN
- Updates model weights online (if enabled)
- Caches previous rides to reduce inference cost
- Logs latency, RMSE, drift spikes, and error outliers
- Visualizes all data on an elegant Streamlit UI

---

## ğŸ–¼ï¸ UI Preview

<p align="center">
  <img src="https://github.com/rajesh1804/RideCastAI2.0/raw/main/assets/RideCastAI2.0-demo.gif" width="750"/>
</p>

**Tabbed layout includes:**

- ğŸ”® **Live Prediction** â€” Real-time results + top-5 worst errors  
- âš ï¸ **Drift & Metrics** â€” Input + Output drift tracking + RMSE overlay  
- âš¡ **Latency Monitor** â€” Inference timing graph  
- ğŸ”§ **Settings** â€” Inject Drift, Enable Online Learning, View Architecture

ğŸ“Œ Try the live app here:  
ğŸ‘‰ [RideCastAI 2.0 â€“ Hugging Face Space](https://huggingface.co/spaces/rajesh1804/RideCastAI2.0)

---

## ğŸ§ª Sample Output (Ride ID: `ride_1027`)

- **ğŸš• Predicted Fare**: â‚¹184.76  
- **ğŸš• Predicted ETA**: 12.4 minutes  
- **ğŸ“Š RMSE (Last 50)**: Fare: â‚¹9.12 | ETA: 1.8 mins  
- **ğŸ“‰ Drift**:  
  - Input: âŒ No  
  - Output: âœ… ADWIN Triggered  
- **Latency**: 1.2s  
- **In Top-5 Error**: âœ… Yes â†’ Underestimated ETA by 4.9 mins

---

## ğŸ“ Project Structure

```bash
RideCastAI2.0/
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py                     # Streamlit frontend
â”œâ”€â”€ model/
â”‚   â””â”€â”€ river_models.py            # Drift + model logic
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ latency_tracker.py
â”‚   â””â”€â”€ drift_plot_utils.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ rides.csv                  # Input data
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ ridecast_architecture.png  # Arch Diagram
â”‚   â””â”€â”€ ridecast_demo.gif          # UI Demo
â””â”€â”€ requirements.txt
```

---

## ğŸ’¼ Why This Project Stands Out

- âœ… Real-time architecture, not just static ML
- âœ… Combines **drift detection + online learning + latency awareness**
- âœ… Debuggable like internal Uber/Lyft tools
- âœ… Clean, modular UI with tabbed monitoring
- âœ… Designed for **free-tier deployability** with zero cost
- âœ… Built as a candidate portfolio app to demonstrate elite ML engineering

---

## ğŸ§° Run Locally (for Devs)

```bash
git clone https://github.com/rajesh1804/RideCastAI2.0
cd RideCastAI2.0
pip install -r requirements.txt
streamlit run ui/app.py
```

---

## ğŸ§  Linked Projects

| Project              | Description                                                              | Link |
|----------------------|---------------------------------------------------------------------------|------|
| ğŸ§µ ThreadNavigatorAI 2.0 | Multi-Agent Reddit thread analyzer with LLM-as-a-Judge                  | [ğŸ”— View](https://github.com/rajesh1804/ThreadNavigatorAI2.0) |
| ğŸ›’ GroceryGPT+          | Vector search + reranking grocery assistant with fuzzy recall             | [ğŸ”— View](https://github.com/rajesh1804/GroceryGPT) |
| ğŸ¬ StreamWiseAI         | Netflix-style movie recommender with Retention Coach Agent                | [ğŸ”— View](https://github.com/rajesh1804/StreamWiseAI) |

---

## âš ï¸ Known Challenges

- ğŸ§± `river` failed to install on Hugging Face (Rust required) â†’ solved via downgrade to `river==0.15.1`
- ğŸŒ€ Drift injection needed careful UI/UX isolation â€” solved with toggle + sidebar logs
- ğŸ§  ONNX conversion limited to scikit-learn baseline only (not River) â€” handled fallback with hybrid logic
- ğŸ•’ Async scheduler in Streamlit was tricky â€” solved using `asyncio.create_task` + stateful cache

---

## ğŸ§‘â€ğŸ’¼ About Me

**Rajesh Marudhachalam** â€” AI/ML Engineer building real-time, agentic, and production-grade AI systems.  
ğŸ“ [GitHub](https://github.com/rajesh1804) | [LinkedIn](https://www.linkedin.com/in/rajesh1804/)

Projects: [ThreadNavigatorAI2.0](https://github.com/rajesh1804/ThreadNavigatorAI2.0), [StreamWiseAI](https://github.com/rajesh1804/StreamWiseAI), [GroceryGPT+](https://github.com/rajesh1804/GroceryGPT)

---

## ğŸ™Œ Acknowledgments

- [River](https://riverml.xyz) â€” Streaming ML + Drift Detection  
- [Streamlit](https://streamlit.io) â€” UI Framework  
- [Hugging Face Spaces](https://huggingface.co/spaces) â€” App Hosting

---

## ğŸ“œ License

MIT License

â­ï¸ *Star this repo if it impressed you. Follow for more production-grade ML builds.*
